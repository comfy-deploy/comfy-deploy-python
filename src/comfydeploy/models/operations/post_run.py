"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from comfydeploy.models.components import httpmetadata as components_httpmetadata
from comfydeploy.types import BaseModel
from enum import Enum
import pydantic
from typing import Any, Dict, Optional, TypedDict, Union
from typing_extensions import Annotated, NotRequired


class Gpu(str, Enum):
    T4 = "T4"
    L4 = "L4"
    A10_G = "A10G"
    A100 = "A100"
    A100_80_GB = "A100-80GB"
    H100 = "H100"

class RunOrigin(str, Enum):
    MANUAL = "manual"
    API = "api"
    PUBLIC_SHARE = "public-share"
    PUBLIC_TEMPLATE = "public-template"
    WORKSPACE = "workspace"

InputsTypedDict = Union[str, float]


Inputs = Union[str, float]


class PostRunRequestBodyTypedDict(TypedDict):
    r"""Run options"""
    
    deployment_id: NotRequired[str]
    r"""Deployment ID to run"""
    workflow_api: NotRequired[Any]
    r"""Workflow API JSON to run"""
    workflow_api_json: NotRequired[str]
    r"""Workflow API JSON to run"""
    workflow_id: NotRequired[str]
    r"""Workflow ID to run"""
    machine_id: NotRequired[str]
    gpu: NotRequired[Gpu]
    concurrency_limit: NotRequired[float]
    private_volume_name: NotRequired[str]
    timeout: NotRequired[float]
    run_origin: NotRequired[RunOrigin]
    inputs: NotRequired[Dict[str, InputsTypedDict]]
    r"""External inputs to the workflow"""
    inputs_json: NotRequired[str]
    r"""External inputs to the workflow in JSON format"""
    webhook: NotRequired[str]
    r"""Webhook URL to receive workflow updates"""
    webhook_intermediate_status: NotRequired[bool]
    r"""Whether to send webhook on intermediate status"""
    stream: NotRequired[bool]
    r"""Whether to return a streaming url"""
    batch_number: NotRequired[float]
    r"""Batch number to run"""
    

class PostRunRequestBody(BaseModel):
    r"""Run options"""
    
    deployment_id: Optional[str] = None
    r"""Deployment ID to run"""
    workflow_api: Optional[Any] = None
    r"""Workflow API JSON to run"""
    workflow_api_json: Optional[str] = None
    r"""Workflow API JSON to run"""
    workflow_id: Optional[str] = None
    r"""Workflow ID to run"""
    machine_id: Optional[str] = None
    gpu: Optional[Gpu] = None
    concurrency_limit: Optional[float] = None
    private_volume_name: Optional[str] = None
    timeout: Optional[float] = None
    run_origin: Optional[RunOrigin] = None
    inputs: Optional[Dict[str, Inputs]] = None
    r"""External inputs to the workflow"""
    inputs_json: Optional[str] = None
    r"""External inputs to the workflow in JSON format"""
    webhook: Optional[str] = None
    r"""Webhook URL to receive workflow updates"""
    webhook_intermediate_status: Optional[bool] = None
    r"""Whether to send webhook on intermediate status"""
    stream: Optional[bool] = None
    r"""Whether to return a streaming url"""
    batch_number: Optional[float] = 1
    r"""Batch number to run"""
    

class PostRunResponseBodyTypedDict(TypedDict):
    r"""Workflow queued"""
    
    run_id: str
    

class PostRunResponseBody(BaseModel):
    r"""Workflow queued"""
    
    run_id: str
    

class PostRunResponseTypedDict(TypedDict):
    http_meta: components_httpmetadata.HTTPMetadataTypedDict
    object: NotRequired[PostRunResponseBodyTypedDict]
    r"""Workflow queued"""
    

class PostRunResponse(BaseModel):
    http_meta: Annotated[Optional[components_httpmetadata.HTTPMetadata], pydantic.Field(exclude=True)] = None
    object: Optional[PostRunResponseBody] = None
    r"""Workflow queued"""
    
